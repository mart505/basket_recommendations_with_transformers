{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZWH6TUGM6rB"
   },
   "source": [
    "# **Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7917,
     "status": "ok",
     "timestamp": 1647184291084,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "MhPiWNheNaw1"
   },
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.models import BPE, WordLevel\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import BpeTrainer, WordLevelTrainer\n",
    "from transformers import PreTrainedTokenizerFast, BertForPreTraining\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "import random\n",
    "from math import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1647184291087,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "uOvhuYP1mCoS"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtgDA4KBNelG",
    "tags": []
   },
   "source": [
    "# **Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'TRAIN_PATH' \n",
    "TOKENIZER_PATH = 'TOKENIZER_PATH'\n",
    "CHECKPOINTS_PATH = 'CHECKPOINTS_PATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4608,
     "status": "ok",
     "timestamp": 1647184295687,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "T5Rzu-K3NhFY"
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(TRAIN_PATH, header=None, nrows=1250000)#,nrows=500000)\n",
    "df.columns = [\"baskets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647184295688,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "Tu-vhp2dCVuJ"
   },
   "outputs": [],
   "source": [
    "df_org = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1647184296144,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "tgkk8psFOjPa",
    "outputId": "0b997aef-6c45-478e-b02e-8aa1156746ab"
   },
   "outputs": [],
   "source": [
    "df_org.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1647184296358,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "zNAlPxvUPAKj"
   },
   "outputs": [],
   "source": [
    "baskets = df['baskets'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1488,
     "status": "ok",
     "timestamp": 1647184297843,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "CJiO9GgS3y5m"
   },
   "outputs": [],
   "source": [
    "txt_file = open(\"/tmp/baskets.txt\", \"w\")\n",
    "for element in baskets:\n",
    "    txt_file.write(element + \"\\n\")\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4859,
     "status": "ok",
     "timestamp": 1647184302698,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "xiBlhuXaCVuL"
   },
   "outputs": [],
   "source": [
    "baskets_set = [basket.split() for basket in baskets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1647184302968,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "w95C96BXCVuL"
   },
   "outputs": [],
   "source": [
    "basket_items = []\n",
    "\n",
    "for basket in baskets_set:\n",
    "    basket_items.extend(basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1995,
     "status": "ok",
     "timestamp": 1647184304960,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "Mo4-TKPsCVuL",
    "outputId": "a4a61f70-3f49-4553-c414-f8d7cb780072"
   },
   "outputs": [],
   "source": [
    "words = len(set(basket_items))\n",
    "print(f'{words} unique items in baskets...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC0CflsmUh_f"
   },
   "source": [
    "# **Universal Tokenizer**\n",
    "\n",
    "Only run the code commented below, if you wish to make a new tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647184304961,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "fIfcMuaEbS40"
   },
   "outputs": [],
   "source": [
    "# trainer = WordLevelTrainer(special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"],vocab_size=words+5) # Amount of products plus 5 special tokens is 30779\n",
    "\n",
    "# new_tokenizer = Tokenizer(WordLevel(unk_token=\"<unk>\"))\n",
    "# new_tokenizer.pre_tokenizer = WhitespaceSplit()\n",
    "\n",
    "# files = [\"/tmp/baskets.txt\"]\n",
    "# new_tokenizer.train(files, trainer)\n",
    "\n",
    "# new_tokenizer.post_processor = TemplateProcessing(\n",
    "#     single=f\"<s>:0 $A:0 </s>:0\",\n",
    "#     pair=f\"<s>:0 $A:0 </s>:0 $B:1 </s>:1\",\n",
    "#     special_tokens=[(\"<s>\", new_tokenizer.token_to_id(\"<s>\")), \n",
    "#                     (\"</s>\", new_tokenizer.token_to_id(\"</s>\"))]\n",
    "# )\n",
    "\n",
    "# new_tokenizer.save(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2xwW5GCCVuM"
   },
   "source": [
    "## *TF GPT-2* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7477,
     "status": "ok",
     "timestamp": 1647184312432,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "tGZWtw57CVuN"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Config, TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from transformers import PreTrainedTokenizerFast, BertForPreTraining, AdamWeightDecay\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1647184312701,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "WbjLtl6VCVuN",
    "outputId": "67c18ea0-b664-401f-f4af-02a288568daa"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22639,
     "status": "ok",
     "timestamp": 1647184335339,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "pGEA3eOWCVuN",
    "outputId": "d9d53100-9c06-45e1-d29a-4f91091571e2"
   },
   "outputs": [],
   "source": [
    "# loading tokenizer from the saved model path\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=TOKENIZER_PATH, # You can load from the tokenizer file, alternatively\n",
    "    eos_token= \"</s>\",\n",
    "    bos_token= \"<s>\",\n",
    "    unk_token= \"<unk>\",\n",
    "    pad_token= \"<pad>\",\n",
    "    mask_token= \"<mask>\",\n",
    "    cls_token=\"<s>\",\n",
    "    sep_token=\"</s>\"\n",
    ")\n",
    "# creating the configurations from which the model can be made\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    use_cache=False\n",
    ")\n",
    "# creating the model\n",
    "#possibily load model from checkpoint\n",
    "#gpt_model = TFGPT2LMHeadModel(config).from_pretrained(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1647184335340,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "lidDG9QdCVuO",
    "outputId": "34670046-96f6-4dbb-f443-4a7bed2cb23b"
   },
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43689,
     "status": "ok",
     "timestamp": 1647184379025,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "dyKlzWeJCVuO"
   },
   "outputs": [],
   "source": [
    "train_single_sentence = \"\"\n",
    "val_single_sentence = \"\"\n",
    "\n",
    "for i, basket in enumerate(baskets):\n",
    "    if i < 0.8*len(baskets):\n",
    "        train_single_sentence += basket + ' ' + tokenizer.eos_token + ' '\n",
    "    elif i >= 0.8*len(baskets):\n",
    "        val_single_sentence += basket + ' ' + tokenizer.eos_token + ' '\n",
    "    \n",
    "train_string_tokenized = tf.squeeze(tokenizer.encode(train_single_sentence, add_special_tokens=False, return_tensors='tf'))\n",
    "val_string_tokenized = tf.squeeze(tokenizer.encode(val_single_sentence, add_special_tokens=False, return_tensors='tf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 65607,
     "status": "ok",
     "timestamp": 1647184444616,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "eQDI5eI4CVuO"
   },
   "outputs": [],
   "source": [
    "train_examples, val_examples = [], []\n",
    "\n",
    "BLOCK_SIZE = 60 # Block size indicates the sequence length used by the model\n",
    "BATCH_SIZE = 12\n",
    "BUFFER_SIZE = 1000\n",
    "LEARNING_RATE=2e-5\n",
    "DISABLE_LR_SCHEDULE=True\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "\n",
    "for i in range(0, len(train_string_tokenized) - BLOCK_SIZE + 1, BLOCK_SIZE):\n",
    "    train_examples.append(train_string_tokenized[i:i + BLOCK_SIZE])\n",
    "    \n",
    "for i in range(0, len(val_string_tokenized) - BLOCK_SIZE + 1, BLOCK_SIZE):\n",
    "    val_examples.append(val_string_tokenized[i:i + BLOCK_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 143813,
     "status": "ok",
     "timestamp": 1647184588416,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "B7aUNyOJCVuP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, train_labels = [], []\n",
    "val_inputs, val_labels = [], []\n",
    "\n",
    "for ex in train_examples:\n",
    "    train_inputs.append(ex[:-1])\n",
    "    train_labels.append(ex[1:])\n",
    "    \n",
    "    \n",
    "for ex in val_examples:\n",
    "    val_inputs.append(ex[:-1])\n",
    "    val_labels.append(ex[1:])\n",
    "    \n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inputs, val_labels))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647184588417,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "Z3bEZjFYCVuP"
   },
   "outputs": [],
   "source": [
    "class Checkpoint(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dir):\n",
    "        super(Checkpoint, self).__init__()\n",
    "\n",
    "        self.dir = dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        checkpoint_dir = os.path.join(self.dir, f'checkpoint-{epoch}')\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.model.save_pretrained(checkpoint_dir)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        checkpoint_dir = os.path.join(self.dir, 'final_epoch')\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.model.save_pretrained(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647184588417,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "IieT_7aLCVuP"
   },
   "outputs": [],
   "source": [
    "class PPL(object):\n",
    "    def __init__(self, name):\n",
    "        self.__name__ = name\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        cross_entropy = K.sparse_categorical_crossentropy(\n",
    "            y_true, y_pred, from_logits=True)\n",
    "\n",
    "        ppl = math.e ** K.mean(cross_entropy)\n",
    "\n",
    "        return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1647184588417,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "VnfHLqOgCVuP"
   },
   "outputs": [],
   "source": [
    "class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"Applys a warmup schedule on a given learning rate decay schedule.\"\"\"\n",
    "\n",
    "    def __init__(self, initial_learning_rate, decay_schedule_fn, warmup_steps, power=1.0, name=None):\n",
    "        super().__init__()\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.power = power\n",
    "        self.decay_schedule_fn = decay_schedule_fn\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name or \"WarmUp\") as name:\n",
    "            # Implements polynomial warmup. i.e., if global_step < warmup_steps, the\n",
    "            # learning rate will be `global_step/num_warmup_steps * init_lr`.\n",
    "            global_step_float = tf.cast(step, tf.float32)\n",
    "            warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)\n",
    "            warmup_percent_done = global_step_float / warmup_steps_float\n",
    "            warmup_learning_rate = self.initial_learning_rate * \\\n",
    "                tf.math.pow(warmup_percent_done, self.power)\n",
    "            return tf.cond(\n",
    "                global_step_float < warmup_steps_float,\n",
    "                lambda: warmup_learning_rate,\n",
    "                lambda: self.decay_schedule_fn(step),\n",
    "                name=name,\n",
    "            )\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"decay_schedule_fn\": self.decay_schedule_fn,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"power\": self.power,\n",
    "            \"name\": self.name,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647184588418,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "-ErXG_xXCVuQ"
   },
   "outputs": [],
   "source": [
    "class WarmUpLinearDecayScheduler(keras.callbacks.Callback):\n",
    "    \"\"\"Cosine decay with warmup learning rate scheduler\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 learning_rate_base,\n",
    "                 total_steps,\n",
    "                 global_step_init=0,\n",
    "                 warmup_learning_rate=0.0,\n",
    "                 warmup_steps=0,\n",
    "                 hold_base_rate_steps=0,\n",
    "                 verbose=0):\n",
    "        \"\"\"Constructor for cosine decay with warmup learning rate scheduler.\n",
    "    Arguments:\n",
    "        learning_rate_base {float} -- base learning rate.\n",
    "        total_steps {int} -- total number of training steps.\n",
    "    Keyword Arguments:\n",
    "        global_step_init {int} -- initial global step, e.g. from previous checkpoint.\n",
    "        warmup_learning_rate {float} -- initial learning rate for warm up. (default: {0.0})\n",
    "        warmup_steps {int} -- number of warmup steps. (default: {0})\n",
    "        hold_base_rate_steps {int} -- Optional number of steps to hold base learning rate\n",
    "                                    before decaying. (default: {0})\n",
    "        verbose {int} -- 0: quiet, 1: update messages. (default: {0})\n",
    "        \"\"\"\n",
    "\n",
    "        super(WarmUpLinearDecayScheduler, self).__init__()\n",
    "        self.learning_rate_base = learning_rate_base\n",
    "        self.total_steps = total_steps\n",
    "        self.global_step = global_step_init\n",
    "        self.warmup_learning_rate = warmup_learning_rate\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.hold_base_rate_steps = hold_base_rate_steps\n",
    "        self.verbose = verbose\n",
    "        self.learning_rates = []\n",
    "\n",
    "        learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "            initial_learning_rate=learning_rate_base, decay_steps=total_steps, end_learning_rate=0.0\n",
    "        )\n",
    "\n",
    "        self.sched = WarmUp(learning_rate_base,\n",
    "                            learning_rate_fn, warmup_steps=warmup_steps)\n",
    "        \n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.global_step = self.global_step + 1\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        self.learning_rates.append(lr)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "\n",
    "        # lr = cosine_decay_with_warmup(global_step=self.global_step,\n",
    "        #                               learning_rate_base=self.learning_rate_base,\n",
    "        #                               total_steps=self.total_steps,\n",
    "        #                               warmup_learning_rate=self.warmup_learning_rate,\n",
    "        #                               warmup_steps=self.warmup_steps,\n",
    "        #                               hold_base_rate_steps=self.hold_base_rate_steps)\n",
    "\n",
    "        lr = self.sched(self.global_step)\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nBatch %05d: setting learning '\n",
    "                  'rate to %s.' % (self.global_step + 1, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3283,
     "status": "ok",
     "timestamp": 1647184591696,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "mVgZY6W_CVuQ"
   },
   "outputs": [],
   "source": [
    "n_train_steps = int(len(list(train_dataset))) * NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647184591697,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "QhFW2x2oCVuS"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = Checkpoint('/content/drive/MyDrive/Seminar QM/Models/TF/AH GPT 625k Pretraining')\n",
    "lr_callback = WarmUpLinearDecayScheduler(learning_rate_base=LEARNING_RATE, \n",
    "                                         total_steps=n_train_steps, \n",
    "                                         warmup_steps=int(0.1 * n_train_steps))\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "val_ppl = PPL('ppl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1647184591698,
     "user": {
      "displayName": "Martijn Korf",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01488148889324962593"
     },
     "user_tz": -60
    },
    "id": "nxm9Hy_SCVuT"
   },
   "outputs": [],
   "source": [
    "# defining our optimizer\n",
    "optimizer = AdamWeightDecay(learning_rate=LEARNING_RATE, weight_decay_rate=0.01)\n",
    "# definining our loss function\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# defining our metric which we want to observe\n",
    "val_acc = tf.keras.metrics.SparseCategoricalAccuracy('acc')\n",
    "val_acc_k = tf.keras.metrics.SparseTopKCategoricalAccuracy(name='acc_k',k=6)\n",
    "# compiling the model\n",
    "gpt_model.compile(optimizer=optimizer,\n",
    "             #run_eagerly=True)#, \n",
    "              loss=[loss, *[None] * gpt_model.config.n_layer], \n",
    "              metrics=[val_acc,val_acc_k, val_ppl])\n",
    "gpt_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk9naUGECVuT",
    "outputId": "99a6bd1d-3bb0-481c-9085-468d6a8ebf17"
   },
   "outputs": [],
   "source": [
    "if DISABLE_LR_SCHEDULE:\n",
    "    \n",
    "    history = gpt_model.fit(train_dataset, \n",
    "                            validation_data=val_dataset, \n",
    "                            epochs=NUM_EPOCHS, \n",
    "                            callbacks=[checkpoint_callback, es_callback])\n",
    "else:\n",
    "    \n",
    "    lr_callback = WarmUpLinearDecayScheduler(learning_rate_base=LEARNING_RATE,\n",
    "                                             total_steps=n_train_steps, \n",
    "                                             warmup_steps=int(0.1 * n_train_steps))\n",
    "\n",
    "    history = gpt_model.fit(train_dataset, \n",
    "                            validation_data=val_dataset, \n",
    "                            epochs=NUM_EPOCHS, \n",
    "                            callbacks=[checkpoint_callback, lr_callback, es_callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tf_GPT2_pretrain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
