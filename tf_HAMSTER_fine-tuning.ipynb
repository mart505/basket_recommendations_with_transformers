{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1485,"status":"ok","timestamp":1647177349102,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"},"user_tz":-60},"id":"zUnWQLk_NQlv","outputId":"2811e6ca-667d-49bb-de0b-28eebe47a943"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#Mount Drive for remote data access\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"eu6ce1MNM_g6"},"source":["# **Install packages**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":14393,"status":"ok","timestamp":1647177363491,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"},"user_tz":-60},"id":"ps4-gx1jMce9","outputId":"23ca4b63-b31d-438d-8e85-473aff2562d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.11.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (0.51.2)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba) (1.21.5)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba) (57.4.0)\n"]}],"source":["!pip install transformers\n","!pip install tokenizers\n","!pip install tensorflow\n","!pip install tensorflow_addons\n","!pip install numba"]},{"cell_type":"markdown","metadata":{"id":"wZWH6TUGM6rB"},"source":["# **Import packages**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhPiWNheNaw1"},"outputs":[],"source":["import tensorflow as tf\n","#from tensorflow_addons.optimizers import AdamW\n","from tensorflow.python.client import device_lib\n","import transformers\n","\n","import warnings\n","from tokenizers.processors import TemplateProcessing\n","from tokenizers.pre_tokenizers import WhitespaceSplit\n","from tokenizers.models import BPE\n","from tokenizers import Tokenizer\n","from tokenizers.trainers import BpeTrainer\n","from transformers import PreTrainedTokenizerFast, BertForPreTraining\n","from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n","from transformers import pipeline, set_seed, GPT2Model, GPT2Config, GPT2Tokenizer, TFGPT2LMHeadModel, TFBertForSequenceClassification, AdamW, BertConfig, TFBertForNextSentencePrediction\n","\n","from sklearn.model_selection import train_test_split, ShuffleSplit, KFold\n","from hyperopt import hp, fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n","import logging \n","logging.basicConfig(level=logging.ERROR)\n","import random\n","from math import *\n","from tqdm import tqdm, notebook\n","import pandas as pd\n","import numpy as np\n","\n","import os"]},{"cell_type":"markdown","metadata":{"id":"CtgDA4KBNelG"},"source":["# **Import and view data**"]},{"cell_type":"markdown","source":["Paths"],"metadata":{"id":"4lltQj6NEw5S"}},{"cell_type":"code","source":["path_data_train = \"\"\n","path_data_test = \"\"\n","path_tokenizer = \"\"\n","path_gpt_pre = \"\"\n","path_bert_pre = \"\"\n","save_path = \"\"\n","path_final_metrics = \"\"\n","path_save_gpt = \"\"\n","path_save_bert = \"\""],"metadata":{"id":"-AvuGQKyEwfV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOXTK1cli59P"},"source":["Importing and Showing Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T5Rzu-K3NhFY"},"outputs":[],"source":["#import from drive\n","df_org = pd.read_csv(path_data_train, names=[\"prod_series\"])\n","baskets = df_org['prod_series'].to_list()\n","\n","global RANDOM_STATE\n","RANDOM_STATE = 123\n","random.seed(RANDOM_STATE)\n","tf.random.set_seed(RANDOM_STATE)\n","\n","kfold = KFold(n_splits=2, shuffle=True, random_state=RANDOM_STATE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1647177367769,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"},"user_tz":-60},"id":"c0-q2giSq0bD","outputId":"fc4e05b4-2183-4c9f-e03a-480c8f61155a"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 24999 entries, 0 to 24998\n","Data columns (total 1 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   prod_series  24999 non-null  object\n","dtypes: object(1)\n","memory usage: 195.4+ KB\n"]}],"source":["df_test = pd.read_csv(path_data_test, names=[\"prod_series\"], dtype=str)\n","baskets_test = df_test['prod_series'].to_list()\n","df_test.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1647177367769,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"},"user_tz":-60},"id":"jDkQdqJnReD9","outputId":"201fa9ff-03bc-49fb-e532-c2e6fe92ec93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 54.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n","Sun Mar 13 13:16:07 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"9gcbgoZYjGZb"},"source":["Importing Tokenizer and Creating BasketDataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1647177367769,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"},"user_tz":-60},"id":"1Vw4ypSu0dEM","outputId":"e61d8b51-ac7b-4215-b764-98c2083831a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["26722\n"]}],"source":["# loading tokenizer from the saved model path\n","tokenizer = PreTrainedTokenizerFast(\n","    tokenizer_file=path_tokenizer, # You can load from the tokenizer file, alternatively\n","    eos_token= \"</s>\",\n","    bos_token= \"<s>\",\n","    unk_token= \"<unk>\",\n","    pad_token= \"<pad>\",\n","    mask_token= \"<mask>\",\n","    padding_side = \"left\"\n",")\n","\n","vocab_size = tokenizer.__len__()\n","print(vocab_size)\n","\n","class BasketDataset:\n","    def __init__(self, baskets, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.baskets = baskets\n","        self.input_ids = []\n","        self.attention_mask = []\n","        self.encodings = self.tokenizer(self.baskets, truncation=True, max_length=60, padding=True)\n","        #complete basket encoding\n","        self.input_ids.append(tf.constant(self.encodings['input_ids']))\n","        self.attention_mask.append(tf.constant(self.encodings['attention_mask']))\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx]\n","    def __len__(self):\n","        return len(self.input_ids)"]},{"cell_type":"markdown","metadata":{"id":"KyJy2jiQoZoP"},"source":["\n","\n","# **GAN**"]},{"cell_type":"markdown","metadata":{"id":"yy6qda2uqi7J"},"source":["Check and append GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165,"status":"ok","timestamp":1647177368624,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"},"user_tz":-60},"id":"LPLUEnmD45wi","outputId":"7feed520-f9a8-4d98-ce6f-81fdda932cd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: /device:GPU:0\n"]}],"source":["# If there's a GPU available...\n","if tf.config.list_physical_devices('GPU'):    \n","    # Tell TensorFlow to use the GPU.    \n","    device = tf.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % len(tf.config.list_physical_devices('GPU')))\n","    print('We will use the GPU:', device_lib.list_local_devices()[1].name)\n","    device_name = device_lib.list_local_devices()[1].name\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = tf.device(\"cpu\")\n","    device_name = device_lib.list_local_devices()[0].name"]},{"cell_type":"markdown","metadata":{"id":"Uf5t4i_LspRk"},"source":["GAN Hyperparamaters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6TQ3XH0s3YB"},"outputs":[],"source":["#Hyperparams\n","bayes_parameters = {'lrD' : hp.uniform('lrD', 1e-7, 2.5e-5),\n","                    'lrG' : hp.uniform('lrG', 1e-7, 1e-5),\n","                    'clipD' : hp.uniform('clipD', 0.75, 1),\n","                    'clipG' : hp.uniform('clipG', 0.5, 1),\n","                    'emb_dropout' : hp.uniform('emb_dropout', 0.05, 0.25),\n","                    'update_ratio' : hp.choice('update_ratio', [2,4])}\n","          \n","params = {\n","    'max_tokenized_length' : 60,\n","    'batch_size' : 4,\n","    'n_seqs' : 6,\n","    'm' : 6,\n","}"]},{"cell_type":"markdown","metadata":{"id":"ZEYZRsTrs81a"},"source":["GAN Procedure"]},{"cell_type":"markdown","metadata":{"id":"201q2qHLCE6j"},"source":["Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8EcBYyKLnz0"},"outputs":[],"source":["global dataset \n","dataset = BasketDataset(baskets, tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"Lekt3h4f97mp"},"source":["Initialize pre-trained models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lImprYsUvbxr"},"outputs":[],"source":["global criterion\n","global real_label \n","global fake_label\n","global bad_words\n","global batches\n","global eos_token\n","global store_values\n","\n","batches = ceil(len(baskets)*(1-1/kfold.n_splits)/params['batch_size'])\n","criterion = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.2, axis=-1)\n","\n","#establish labels\n","real_label = 1\n","fake_label = 0\n","eos_token = 2\n","bad_words = [[tokenizer.eos_token_id],[tokenizer.bos_token_id], [tokenizer.pad_token_id]]"]},{"cell_type":"markdown","metadata":{"id":"zo-JDIdxyQ4W"},"source":["HAMSTER Architechture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WD4tLLuZ7Usc"},"outputs":[],"source":["import json\n","with open('/content/drive/MyDrive/Seminar QM/Data/productIDs_names.txt') as f:\n","    dict_textfile = f.read()     \n","productIDs_names = json.loads(dict_textfile)\n","\n","def getProductNames(A):\n","    if (tf.rank(A) <= 1): # check if rank 1, otherwise tokenizer.decode doesn't work\n","        B = tokenizer.decode(A).split(\" \")\n","        names = [productIDs_names[B[b]] for b in range(len(B)) if B[b] in productIDs_names.keys()]\n","    else:\n","        names = [getProductNames(A[i]) for i in range(len(A))]\n","    return names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKUPLaHX6sLZ"},"outputs":[],"source":["def maligan_rewards(fake_logits_D, b):\n","    dx = tf.math.sigmoid(fake_logits_D)[:]\n","    rewards = dx / (1 - dx)\n","    rewards = (rewards) / sum(rewards) - b\n","    return tf.transpose(rewards)\n","\n","def maligan_loss(fake_logits_G, fake_logits_D, item_pred, b):\n","    # maligan loss for 1 prediction per basket\n","    rewards = maligan_rewards(fake_logits_D, b)\n","    loss_G = -1*tf.reduce_sum(\n","        tf.reduce_sum(\n","            tf.reduce_sum(\n","              tf.one_hot(\n","                  tf.cast(\n","                      tf.reshape(\n","                          item_pred, [-1] \n","                          ), dtype=tf.int32\n","                      ),\n","                  vocab_size, 1.0, 0.0 \n","                  ),\n","                  axis=0\n","            )\n","            * tf.math.log(\n","                tf.clip_by_value(\n","                    tf.reshape(\n","                        tf.nn.softmax(fake_logits_G), [-1, tokenizer.vocab_size]\n","                        ),\n","                    1e-20, 1.0\n","                    )\n","                ),\n","            1\n","            )\n","        * tf.reshape(rewards, [-1])\n","    )\n","    return loss_G"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hyCDSs-KEw5j"},"outputs":[],"source":["def delete_spec_tokens(basket):\n","    for i in range(len(basket)):\n","        basket_num = basket[i].numpy()\n","        basket_num = np.where(basket_num==0, 1, basket_num)\n","        basket_num = np.where(basket_num==2, 1, basket_num)\n","        if i==0:\n","            basket_tok = basket_num\n","        else:\n","            basket_nump = basket_num\n","            basket_tok = np.vstack([basket_tok,basket_nump])\n","    basket_batch_tok = tf.convert_to_tensor(basket_tok, dtype=tf.int32)\n","    return basket_batch_tok"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pcq9wL2e5dZU"},"outputs":[],"source":["def bert_tokens(basket, attention, realfake):\n","    for i in range(len(basket)):\n","      attn_num = attention[i].numpy()\n","      basket_num = basket[i].numpy()\n","\n","      attn_new = np.delete(attn_num, np.where(attn_num==0))\n","      length_padding = np.count_nonzero(basket_num==1)\n","      basket_num[-1] = 2\n","      basket_new = np.delete(basket_num, np.where(basket_num==1))              \n","      if length_padding!=0:\n","        padding_basket = np.full((length_padding-1,), 1)\n","        padding_attn = np.full((length_padding-1,), 0)\n","        basket_a = basket_new[:-2]\n","        basket_b = basket_new[-2:]\n","        basket_final = np.concatenate((basket_a, [2], basket_b, padding_basket))\n","\n","        attn_final = np.concatenate((attn_new,[1], padding_attn))\n","\n","        token_type_zero = np.full((len(attn_num)-len(padding_attn)-2,),0)\n","        token_type = np.concatenate((token_type_zero, [1,1], padding_attn))\n","      else:\n","        attn_final = attn_num\n","        token_type_zero = np.full((len(attn_num)-2,),0)\n","        token_type = np.concatenate((token_type_zero,[1,1]))\n","        basket_a = basket_new[1:-2]\n","        basket_b = basket_new[-2:]\n","        basket_final = np.concatenate((basket_a, [2], basket_b))\n","\n","      if realfake == \"fake\":\n","        basket_final = np.concatenate(([0],basket_final))\n","        basket_final = basket_final[:-1]\n","        token_type = np.concatenate(([0],token_type))\n","        token_type = token_type[:-1]\n","        attn_final = attn_final[:-1]\n","      if i==0:\n","        attn_batch = attn_final\n","        token_batch = token_type\n","        basket_batch = basket_final\n","      else:\n","        attn_nump = attn_final\n","        attn_batch = np.vstack([attn_batch,attn_nump])\n","        token_nump = token_type\n","        token_batch = np.vstack([token_batch,token_nump])\n","        basket_nump = basket_final\n","        basket_batch = np.vstack([basket_batch,basket_nump])\n","      attn_batch_tens = tf.convert_to_tensor(attn_batch, dtype=tf.int32) \n","      token_batch_tens = tf.convert_to_tensor(token_batch, dtype=tf.int32)\n","      basket_batch_tens = tf.convert_to_tensor(basket_batch, dtype=tf.int32)\n","    return basket_batch_tens, attn_batch_tens, token_batch_tens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vLUou2fyzcA"},"outputs":[],"source":["def gan_finetuning(space):\n","\n","    store_values = np.array([0,1,2,3,4,5,6])    # iter, correctD_real, correctD_fake, loss G, loss D, precK running average, prekK iter\n","    lr_D, lr_G = space['lrD'], space['lrG']\n","    clip_D, clip_G = space['clipD'], space['clipG']\n","    num_epochs = 1\n","    b_size = params['batch_size']\n","    m = params['m']\n","    k= params['n_seqs']\n","    update_ratio = space['update_ratio']\n","    emb_dropout= space['emb_dropout']\n","    attn_dropout= 0.0\n","    early_stop = False\n","    status_hyp = STATUS_OK\n","\n","\n","    fnl_prec_k,fnl_loss_G,fnl_loss_D = [],[],[]\n","    prec_k_final = 0\n","\n","    for train_index, val_index in kfold.split(dataset.input_ids[0]):\n","        #initialize variables\n","\n","        losses_G, losses_D = [], []\n","        avg_loss_G, avg_loss_D = 0,0\n","        train_input, val_input = {}, {}\n","\n","        train_input['input_ids'] = tf.gather(dataset.input_ids[0], indices=tf.constant(train_index))\n","        train_input['attention_mask'] = tf.gather(dataset.attention_mask[0], indices=tf.constant(train_index))\n","        \n","        val_input['input_ids'] = tf.gather(dataset.input_ids[0], indices=tf.constant(val_index))\n","        val_input['attention_mask'] = tf.gather(dataset.attention_mask[0], indices=tf.constant(val_index))\n","        \n","        #initialize models and optimizers\n","        net_G = TFGPT2LMHeadModel.from_pretrained(path_gpt_pre,\n","                                                  embd_pdrop=emb_dropout,       #dropout for the hidden layers\n","                                                  attn_pdrop=attn_dropout)  #dropout for the attention heads\n","        optim_G = tf.keras.optimizers.Adam(lr_G, clipnorm=clip_G)\n","\n","        net_D = TFBertForSequenceClassification.from_pretrained(path_bert_pre, num_labels=1)\n","        optim_D = tf.keras.optimizers.Adam(lr_D, clipnorm=clip_D)\n","\n","        for epoch in range(num_epochs):\n","            train_correct = 0\n","            real_correct_D = 0\n","            fake_correct_D = 0\n","            correct_G = 0\n","\n","            train_loader = tf.data.Dataset.from_tensor_slices((train_input['input_ids'], \n","                                                               train_input['attention_mask']\n","                                                              )).batch(b_size) \n","            \n","            train_loop = notebook.tqdm(train_loader, position=0, leave=True, colour='green')\n","\n","            for t, batch in enumerate(train_loop):\n","                correctD_real_ITER, correctD_fake_ITER, train_correct_ITER = 0,0,0\n","\n","                real_input_ids = batch[0]\n","                real_attention_mask = batch[1]\n","                missing_item = real_input_ids[:,-2]\n","                \n","                real_labels = tf.fill([b_size,1],real_label) # real_label = 1\n","                \n","                # create Generator input and new attention mask due to shifted padding and removal of special tokens\n","                inc_input_ids = delete_spec_tokens(real_input_ids)\n","                inc_input_ids = inc_input_ids[:,0:-2]\n","                inc_attention_mask = tf.where(~(inc_input_ids!=1),tf.fill(real_attention_mask[:,0:-2].shape,0),1)\n","                \n","                with tf.GradientTape() as tape_G, tf.GradientTape() as tape_D:\n","                    #forward pass real data\n","                    tape_D.watch(net_D.trainable_variables)\n","                    tape_G.watch(net_G.trainable_variables)\n","          \n","                    #switch padding\n","                    real_input_ids_sw, real_attention_mask_sw, real_token_type_ids_sw = bert_tokens(real_input_ids, real_attention_mask, realfake=\"real\")\n","                    #output discriminator on real data\n","                    real_logits_D = net_D.call(input_ids=real_input_ids_sw,\n","                                               attention_mask=real_attention_mask_sw,\n","                                               token_type_ids=real_token_type_ids_sw,\n","                                               training=True).logits\n","                    \n","                    real_sigmoid_D = tf.math.sigmoid(real_logits_D)\n","                    real_loss_D = criterion(real_labels, real_logits_D) #BCE is specified to use logits\n","                    \n","                    #forward pass fake data through generator\n","                    fake_logits_G = net_G.call(input_ids=inc_input_ids,\n","                                               attention_mask=inc_attention_mask,\n","                                               training = True).logits[:,-1,5:]\n","                    fake_logits_adj_G = tf.concat((tf.fill([b_size,5],-100000.0), fake_logits_G), axis=-1) # set logits of first 5 tokens to -100 to rule out              \n","                    fake_softmax_G = tf.nn.softmax(fake_logits_adj_G)\n","                    \n","                    # sample m items from G according to the softmax probalities\n","                    fake_probs_G = np.array([fake_softmax_G[i,:]/np.sum(fake_softmax_G[i,:]) for i in range(b_size)])\n","                    fake_samples_G = np.array([np.random.choice(range(0,tokenizer.vocab_size), \n","                                                                m, \n","                                                                p=fake_probs_G[i,:]) for i in range(b_size)], dtype=np.int32)\n","\n","\n","                    #forward pass of generated samples to discriminator\n","                    fake_top_k = tf.nn.top_k(fake_softmax_G, k=k, sorted=True)[1]\n","                    \n","                    fake_input_ids = tf.concat([inc_input_ids,\n","                                                tf.reshape(fake_top_k[:,0],\n","                                                           [b_size,1]), \n","                                                tf.fill((b_size,1), 2)], #seperator token\n","                                               1)\n","\n","                    fake_input_ids_sw, fake_attention_mask_sw, fake_token_type_ids_sw = bert_tokens(fake_input_ids, real_attention_mask, realfake=\"fake\")\n","                    \n","                    fake_logits_D = net_D.call(input_ids=fake_input_ids_sw,\n","                                               attention_mask=fake_attention_mask_sw,\n","                                               token_type_ids=fake_token_type_ids_sw,\n","                                               training=True).logits\n","                    fake_sigmoid_D = tf.math.sigmoid(fake_logits_D)\n","                    \n","                    for i in range(0,b_size):\n","                        for j in range(0, k):\n","                            if (fake_top_k[i][j] == missing_item[i]):\n","                                train_correct+=1\n","                                train_correct_ITER +=1\n","                                break\n","                    \n","                    #check if fake generated basket is 'not fake'\n","                    if tf.math.equal(tf.reduce_sum(fake_input_ids[:,-2]), tf.reduce_sum(real_input_ids[:,-2])) == False:\n","                        for i in range(len(fake_input_ids)): # loop over batchsize\n","                            if i == 0:\n","                                if real_input_ids[i,-2] != fake_input_ids[i,-2]:\n","                                    fake_labels = tf.fill([1,1],[fake_label])\n","                                elif real_input_ids[i,-2] == fake_input_ids[i,-2]:\n","                                    fake_labels = tf.fill([1,1],[real_label])\n","                            else:\n","                                if real_input_ids[i,-2] != fake_input_ids[i,-2]:\n","                                    step = tf.fill([1,1],[fake_label])\n","                                    fake_labels = tf.concat((fake_labels, step), axis=0)\n","                                elif real_input_ids[i,-2] == fake_input_ids[i,-2]:\n","                                    step = tf.fill([1,1],[real_label])\n","                                    fake_labels = tf.concat((fake_labels, step), axis=0)\n","                                    correct_G+=1\n","                    else:\n","                        fake_labels = tf.fill([b_size,1],[real_label])\n","                \n","                    fake_loss_D = criterion(fake_labels, fake_logits_D)\n","                    \n","                    loss_D = real_loss_D + fake_loss_D\n","                    \n","                    losses_D.append(loss_D.numpy())\n","                    \n","                    # test discriminator\n","                    for i in range(0,b_size):\n","                        if real_sigmoid_D[i] > 0.5: # when real sigmoid is leaning to label = 0, which is correct\n","                            real_correct_D += 1\n","                            correctD_real_ITER +=1\n","                        if (fake_sigmoid_D[i] > 0.5) and fake_labels[i]==1: # when fake sigmoid is leaning to correct label = 1\n","                            fake_correct_D += 1\n","                            correctD_fake_ITER +=1\n","                        elif (fake_sigmoid_D[i] < 0.5) and fake_labels[i]==0: # when fake sigmoid is leaning to correct label = 0\n","                            fake_correct_D += 1\n","                            correctD_fake_ITER +=1\n","                    \n","                    D_correct_ratio = (real_correct_D + fake_correct_D)  / (2*b_size*(t+1))\n","\n","                    # Calculate generator loss\n","                    b = t/(batches)\n","                    loss_G = tf.constant(0.0)\n","                    predicted_items = fake_input_ids_sw[:,-2]\n","                    maligan_w, maligan_dx = [],[]\n","                    \n","                    eos_tokens = tf.fill((m,1), 2)\n","                    \n","                    for i in range(b_size):\n","                        fake_sampled_ids = tf.repeat(tf.reshape(inc_input_ids[i], shape = (1,58)), m, axis=0)\n","        \n","                        \n","                        fake_input_ids_m = tf.concat([fake_sampled_ids,tf.reshape(fake_samples_G[i,:],[m,1]), eos_tokens],1)\n","                        fake_attention_mask_m = tf.repeat(tf.reshape(real_attention_mask[i,:], shape = (1,60)), m, axis=0)\n","                    \n","                        fake_input_ids_m, fake_attention_mask_m, fake_token_type_ids_m = bert_tokens(fake_input_ids_m, \n","                                                                                                   fake_attention_mask_m, \n","                                                                                                   realfake=\"fake\")\n","                        fake_logits_D_m = net_D.call(input_ids=fake_input_ids_m,\n","                                                     attention_mask=fake_attention_mask_m,\n","                                                     token_type_ids=fake_token_type_ids_m,\n","                                                     training=True\n","                                                    ).logits\n","                        fake_sigmoid_D_m = tf.math.sigmoid(fake_logits_D_m)\n","                        maligan_dx.append(fake_sigmoid_D_m[:])                          \n","                        maligan_w.append(maligan_rewards(fake_logits_D_m,b))\n","                        loss_G += maligan_loss(fake_logits_adj_G[i], \n","                                               fake_logits_D_m, \n","                                               tf.reshape(fake_samples_G[i,:],[m,1]), b)\n","                        \n","                    losses_G.append(loss_G.numpy())\n","                    if t%update_ratio==0:  \n","                      grad_G = tape_G.gradient(loss_G, net_G.trainable_variables)\n","                      optim_G.apply_gradients(zip(grad_G, net_G.trainable_variables))\n","                    \n","                    \n","                    grad_D = tape_D.gradient(loss_D, net_D.trainable_variables)\n","                    optim_D.apply_gradients(zip(grad_D, net_D.trainable_variables))\n","        \n","                    train_prec_k = train_correct/((t+1)*b_size)\n","\n","                    if t>0:\n","                      avg_loss_G = sum(losses_G)/t\n","                      avg_loss_D = sum(losses_D)/t\n","                    \n","                    # early stopping condition\n","                    \n","                    if ((train_prec_k < 0.05) and t>(0.05* batches)):\n","                        print('Epoch stopped early...')\n","                        early_stop = True\n","                        break\n","                        status_hyp = 'fail'\n","                    if ((train_prec_k < 0.09) and t>(0.10* batches)):\n","                        print('Epoch stopped early...')\n","                        early_stop = True\n","                        status_hyp = 'fail'\n","                        break\n","                    \n","                    # iter, correctD_real, correctD_fake, loss G, loss D, precK running average, prekK iter\n","                    store_values = np.vstack((store_values,[t,correctD_real_ITER,correctD_real_ITER, loss_G.numpy(), loss_D.numpy(),train_prec_k, train_correct_ITER/b_size ]))\n","                    train_loop.set_postfix(lossG=avg_loss_G, lossD=avg_loss_D, data=\"train\", epochs=num_epochs, \n","                                           G_correct_at1=correct_G, G_total_correct=train_correct, precK=train_prec_k, lrD=lr_D, \n","                                           lrG=lr_G, clipD=clip_D, clipG=clip_G, \n","                                           real_correct_D =real_correct_D, \n","                                           fake_correct_D =fake_correct_D, D_correct_ratio = D_correct_ratio)\n","\n","            #####################################################################################\n","            #start validation\n","            loader_val = tf.data.Dataset.from_tensor_slices((val_input['input_ids'], val_input['attention_mask'])).batch(params['batch_size'])\n","            correct_val = 0   \n","            total_baskets_val = 0\n","            precK_val = 0\n","            loop_val = notebook.tqdm(loader_val, position=0, leave=True, colour='yellow')\n","            for k, batch_val in enumerate(loop_val):\n","              #create incomplete basket\n","              if (early_stop == True) : break\n","              batch_size = len(batch_val[0])\n","              total_baskets_val+=batch_size\n","              non_predict = tf.fill((batch_size,5),0.0)\n","              incomplete_tok_val = delete_spec_tokens(batch_val[0])\n","              incomplete_val = incomplete_tok_val[:,0:-2]\n","              incomplete_mask_val = batch_val[1][:,0:-2]\n","              true_items = batch_val[0][:,-2]\n","              \n","              output_G= net_G.call(input_ids=incomplete_val,\n","                                  attention_mask=incomplete_mask_val, training = False)\n","              #take output layer\n","              outputG_softmax = tf.nn.softmax(output_G.logits[:,-1,5:])\n","              #model should not predict special tokens, therefore, set softmax value at zero\n","              outputG_softmax = tf.concat((non_predict, outputG_softmax), axis=-1)\n","\n","              top_k = tf.nn.top_k(outputG_softmax, k=params['n_seqs'], sorted=False)[1]\n","              top_k_items = tf.squeeze(top_k)\n","\n","              \n","              for i in range(0,batch_size):\n","                for j in range(0, params['n_seqs']):\n","                  if (top_k_items[i][j] == true_items[i]):\n","                    correct_val+=1\n","                    break\n","\n","              precK_val = correct_val/(total_baskets_val)\n","              loop_val.set_postfix(PrecisionAtK =precK_val, Correct=correct_val,  data=\"validation\")\n","\n","        break     \n","\n","    #save results    \n","    fnl_prec_k.append(precK_val)\n","    fnl_loss_G.append(avg_loss_G)\n","    fnl_loss_D.append(avg_loss_D)\n","\n","    folds = kfold.get_n_splits()\n","    prec_k_final = sum(fnl_prec_k)\n","    np.savetxt(f'{save_path}{prec_k_final}_CLIP_{clip_D}.csv', store_values, delimiter=\",\")\n","    \n","    return {'loss': -prec_k_final, 'lossG': sum(fnl_loss_G)/folds, 'lossD': sum(fnl_loss_D)/folds, 'status': status_hyp}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0CpUPTnlAAh"},"outputs":[],"source":["# Run Bayesian Optimization\n","transformers.utils.logging.set_verbosity_error()\n","\n","best_params, lossG, lossD  = dict(), dict(), dict()\n","trials = Trials()\n","best_params = fmin(fn=gan_finetuning,\n","          space=bayes_parameters,\n","          algo=tpe.suggest,\n","          trials=trials,\n","          return_argmin=False, # Return categorical vars as strings instead of indices\n","          max_evals=15,\n","          rstate= np.random.RandomState(RANDOM_STATE))\n","losses  = [x['result']['loss']  for x in trials.trials]\n","lossesG = [x['result']['lossG'] for x in trials.trials]\n","lossesD = [x['result']['lossD'] for x in trials.trials]"]},{"cell_type":"markdown","metadata":{"id":"EetW92_fnXox"},"source":["**TRAIN FULL**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233,"referenced_widgets":["5c6788948c384d59929380ca15c422da","bc18555b6caf4c2a8e18a0fecec5a25a","a734f47d5a5848e18c42fcd10c83d3da","08687923c9934e5a9dbb8a6f76904629","91af8b48709748d189b9fa4d9a4e4d8d","3ac9eb333a0545d58649b0a272b9ea1b","319b495826fc4c99a03aff2366c9c71d","32201219aaf041f1913bf26b9db8696b","89c97ed70d7a4d7e8b895d42355aac4c","5266621c94d64ca99ba067af2f0d1da9","d14e53dcd90243b4a6e6945218270db9"]},"id":"Lj-XJk2sSOrV","executionInfo":{"status":"ok","timestamp":1647203863218,"user_tz":-60,"elapsed":5464514,"user":{"displayName":"martijn korf","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08663037803752538794"}},"outputId":"77fb7e86-46c9-4c8a-ca12-54da2e396497"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at /content/drive/MyDrive/Seminar QM/Models/TF/220306 GPT pre-trained AH (Redding).\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n","All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/Seminar QM/Models/TF/220306 BERT pre-trained AH (REDDING)/bert pre-trained and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c6788948c384d59929380ca15c422da","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["store_values = np.array([0,1,2,3,4,5,6])    # iter, correctD_real, correctD_fake, loss G, loss D, precK running average, prekK iter\n","lr_D, lr_G = best_params['lrD'], best_params['lrG']\n","clip_D, clip_G = best_params['clipD'], best_params['clipG']\n","num_epochs = 1\n","b_size = params['batch_size']\n","m = params['m']\n","k= params['n_seqs']\n","update_ratio = best_params['update_ratio']\n","emb_dropout= best_params['emb_dropout']\n","early_stop = False\n","\n","\n","fnl_prec_k,fnl_loss_G,fnl_loss_D = [],[],[]\n","\n","#initialize variables\n","\n","losses_G, losses_D = [], []\n","avg_loss_G, avg_loss_D = 0,0\n","train_input, val_input = {}, {}\n","\n","train_input['input_ids'] = dataset.input_ids[0]\n","train_input['attention_mask'] = dataset.attention_mask[0]\n","\n","#initialize models and optimizers\n","net_G = TFGPT2LMHeadModel.from_pretrained(path_gpt_pre,\n","                                        embd_pdrop=emb_dropout,       #dropout for the hidden layers\n","                                        attn_pdrop=attn_dropout)      #dropout for the attention heads\n","optim_G = tf.keras.optimizers.Adam(lr_G, clipnorm=clip_G)\n","\n","net_D = TFBertForSequenceClassification.from_pretrained(path_bert_pre, num_labels=1)#, output_hidden_states=True, output_attentions=True)\n","optim_D = tf.keras.optimizers.Adam(lr_D, clipnorm=clip_D)\n","\n","for epoch in range(num_epochs):\n","  train_correct = 0\n","  real_correct_D = 0\n","  fake_correct_D = 0\n","  correct_G = 0\n","\n","  train_loader = tf.data.Dataset.from_tensor_slices((train_input['input_ids'], \n","                                                    train_input['attention_mask']\n","                                                    )).batch(b_size) \n","  \n","  train_loop = notebook.tqdm(train_loader, position=0, leave=True, colour='green')\n","\n","  for t, batch in enumerate(train_loop):\n","      correctD_real_ITER, correctD_fake_ITER, train_correct_ITER = 0,0,0\n","\n","      real_input_ids = batch[0]\n","      real_attention_mask = batch[1]\n","      missing_item = real_input_ids[:,-2]\n","      \n","      real_labels = tf.fill([b_size,1],real_label) # real_label = 1\n","      \n","      # create Generator input and new attention mask due to shifted padding and removal of special tokens\n","      inc_input_ids = delete_spec_tokens(real_input_ids)\n","      inc_input_ids = inc_input_ids[:,0:-2]\n","      inc_attention_mask = tf.where(~(inc_input_ids!=1),tf.fill(real_attention_mask[:,0:-2].shape,0),1)\n","      \n","      with tf.GradientTape() as tape_G, tf.GradientTape() as tape_D:\n","          #forward pass real data\n","          tape_D.watch(net_D.trainable_variables)\n","          tape_G.watch(net_G.trainable_variables)\n","\n","          #switch padding\n","          real_input_ids_sw, real_attention_mask_sw, real_token_type_ids_sw = bert_tokens(real_input_ids, real_attention_mask, realfake=\"real\")\n","          #output discriminator on real data\n","          real_logits_D = net_D.call(input_ids=real_input_ids_sw,\n","                                    attention_mask=real_attention_mask_sw,\n","                                    token_type_ids=real_token_type_ids_sw,\n","                                    training=True).logits\n","          \n","          real_sigmoid_D = tf.math.sigmoid(real_logits_D)\n","          real_loss_D = criterion(real_labels, real_logits_D) #BCE is specified to use logits\n","          \n","          #forward pass fake data through generator\n","          fake_logits_G = net_G.call(input_ids=inc_input_ids,\n","                                    attention_mask=inc_attention_mask,\n","                                    training = True).logits[:,-1,5:]\n","          fake_logits_adj_G = tf.concat((tf.fill([b_size,5],-100000.0), fake_logits_G), axis=-1) # set logits of first 5 tokens to -100 to rule out              \n","          fake_softmax_G = tf.nn.softmax(fake_logits_adj_G)\n","          \n","          # sample m items from G according to the softmax probalities\n","          fake_probs_G = np.array([fake_softmax_G[i,:]/np.sum(fake_softmax_G[i,:]) for i in range(b_size)])\n","          fake_samples_G = np.array([np.random.choice(range(0,tokenizer.vocab_size), \n","                                                      m, \n","                                                      p=fake_probs_G[i,:]) for i in range(b_size)], dtype=np.int32)\n","\n","\n","          #forward pass of generated samples to discriminator\n","          fake_top_k = tf.nn.top_k(fake_softmax_G, k=k, sorted=True)[1]\n","          \n","          fake_input_ids = tf.concat([inc_input_ids,\n","                                      tf.reshape(fake_top_k[:,0],\n","                                                [b_size,1]), \n","                                      tf.fill((b_size,1), 2)], #seperator token\n","                                    1)\n","\n","          fake_input_ids_sw, fake_attention_mask_sw, fake_token_type_ids_sw = bert_tokens(fake_input_ids, real_attention_mask, realfake=\"fake\")\n","          \n","          fake_logits_D = net_D.call(input_ids=fake_input_ids_sw,\n","                                    attention_mask=fake_attention_mask_sw,\n","                                    token_type_ids=fake_token_type_ids_sw,\n","                                    training=True).logits\n","          fake_sigmoid_D = tf.math.sigmoid(fake_logits_D)\n","          \n","          for i in range(0,b_size):\n","              for j in range(0, k):\n","                  if (fake_top_k[i][j] == missing_item[i]):\n","                      train_correct+=1\n","                      train_correct_ITER +=1\n","                      break\n","          \n","          #check if fake generated basket is 'not fake'\n","          if tf.math.equal(tf.reduce_sum(fake_input_ids[:,-2]), tf.reduce_sum(real_input_ids[:,-2])) == False:\n","              for i in range(len(fake_input_ids)): # loop over batchsize\n","                  if i == 0:\n","                      if real_input_ids[i,-2] != fake_input_ids[i,-2]:\n","                          fake_labels = tf.fill([1,1],[fake_label])\n","                      elif real_input_ids[i,-2] == fake_input_ids[i,-2]:\n","                          fake_labels = tf.fill([1,1],[real_label])\n","                  else:\n","                      if real_input_ids[i,-2] != fake_input_ids[i,-2]:\n","                          step = tf.fill([1,1],[fake_label])\n","                          fake_labels = tf.concat((fake_labels, step), axis=0)\n","                      elif real_input_ids[i,-2] == fake_input_ids[i,-2]:\n","                          step = tf.fill([1,1],[real_label])\n","                          fake_labels = tf.concat((fake_labels, step), axis=0)\n","                          correct_G+=1\n","          else:\n","              fake_labels = tf.fill([b_size,1],[real_label])\n","      \n","          fake_loss_D = criterion(fake_labels, fake_logits_D)\n","          \n","          loss_D = real_loss_D + fake_loss_D\n","          \n","          losses_D.append(loss_D.numpy())\n","          \n","          # test discriminator\n","          for i in range(0,b_size):\n","              if real_sigmoid_D[i] > 0.5: # when real sigmoid is leaning to label = 0, which is correct\n","                  real_correct_D += 1\n","                  correctD_real_ITER +=1\n","              if (fake_sigmoid_D[i] > 0.5) and fake_labels[i]==1: # when fake sigmoid is leaning to correct label = 1\n","                  fake_correct_D += 1\n","                  correctD_fake_ITER +=1\n","              elif (fake_sigmoid_D[i] < 0.5) and fake_labels[i]==0: # when fake sigmoid is leaning to correct label = 0\n","                  fake_correct_D += 1\n","                  correctD_fake_ITER +=1\n","          \n","          D_correct_ratio = (real_correct_D + fake_correct_D)  / (2*b_size*(t+1))\n","\n","          # Calculate generator loss\n","          b = t/batches\n","          loss_G = tf.constant(0.0)\n","          predicted_items = fake_input_ids_sw[:,-2]\n","          maligan_w, maligan_dx = [],[]\n","          \n","          eos_tokens = tf.fill((m,1), 2)\n","          \n","          for i in range(b_size):\n","              fake_sampled_ids = tf.repeat(tf.reshape(inc_input_ids[i], shape = (1,58)), m, axis=0)\n","\n","              \n","              fake_input_ids_m = tf.concat([fake_sampled_ids,tf.reshape(fake_samples_G[i,:],[m,1]), eos_tokens],1)\n","              fake_attention_mask_m = tf.repeat(tf.reshape(real_attention_mask[i,:], shape = (1,60)), m, axis=0)\n","          \n","              fake_input_ids_m, fake_attention_mask_m, fake_token_type_ids_m = bert_tokens(fake_input_ids_m, \n","                                                                                        fake_attention_mask_m, \n","                                                                                        realfake=\"fake\")\n","              fake_logits_D_m = net_D.call(input_ids=fake_input_ids_m,\n","                                          attention_mask=fake_attention_mask_m,\n","                                          token_type_ids=fake_token_type_ids_m,\n","                                          training=True\n","                                          ).logits\n","              fake_sigmoid_D_m = tf.math.sigmoid(fake_logits_D_m)\n","              maligan_dx.append(fake_sigmoid_D_m[:])                          \n","              maligan_w.append(maligan_rewards(fake_logits_D_m,b))\n","              loss_G += maligan_loss(fake_logits_adj_G[i], \n","                                    fake_logits_D_m, \n","                                    tf.reshape(fake_samples_G[i,:],[m,1]), b)\n","              \n","          losses_G.append(loss_G.numpy())\n","          if t%update_ratio==0:  \n","            grad_G = tape_G.gradient(loss_G, net_G.trainable_variables)\n","            optim_G.apply_gradients(zip(grad_G, net_G.trainable_variables))\n","          \n","          \n","          grad_D = tape_D.gradient(loss_D, net_D.trainable_variables)\n","          optim_D.apply_gradients(zip(grad_D, net_D.trainable_variables))\n","\n","          train_prec_k = train_correct/((t+1)*b_size)\n","\n","          if t>0:\n","            avg_loss_G = sum(losses_G)/t\n","            avg_loss_D = sum(losses_D)/t\n","          \n","          # early stopping condition\n","          \n","          if ((train_prec_k < 0.05) and t>(0.05* batches)):\n","              print('Epoch stopped early...')\n","              early_stop = True\n","              break\n","          if ((train_prec_k < 0.10) and t>(0.10* batches)):\n","              print('Epoch stopped early...')\n","              early_stop = True\n","              break\n","          \n","          # iter, correctD_real, correctD_fake, loss G, loss D, precK running average, prekK iter\n","          store_values = np.vstack((store_values,[t,correctD_real_ITER,correctD_real_ITER, loss_G.numpy(), loss_D.numpy(),train_prec_k, train_correct_ITER/b_size ]))\n","          train_loop.set_postfix(lossG=avg_loss_G, lossD=avg_loss_D, data=\"train\", epochs=num_epochs, \n","                                G_correct_at1=correct_G, G_total_correct=train_correct, precK=train_prec_k, lrD=lr_D, \n","                                lrG=lr_G, clipD=clip_D, clipG=clip_G, \n","                                real_correct_D =real_correct_D,\n","                                fake_correct_D =fake_correct_D, D_correct_ratio = D_correct_ratio)\n","\n","  \n","  np.savetxt(path_final_metrics, store_values, delimiter=\",\")\n","  net_D.save_pretrained(path_save_bert)\n","  net_G.save_pretrained(path_save_gpt)\n","\n","  #EVERYTHING BELOW SHOULD BE IMPLEMENTED AFTER VALIDATION\n","  fnl_prec_k.append(train_prec_k)\n","  fnl_loss_G.append(avg_loss_G)\n","  fnl_loss_D.append(avg_loss_D)"]},{"cell_type":"code","source":["#-------------------------------------------------------------------------------\n","# ~~~ TEST ~~~ w/ bootstrap only 1 call of netG\n","#-------------------------------------------------------------------------------\n","\n","test_size = 25000\n","num_specialtok = 5\n","top_1_count,top_k_count = 0,0\n","top_1_count_adj, top_k_count_adj = 0,0\n","output = {}\n","total_batches = 0\n","pr_ls_test = []\n","\n","test_basket = {}\n","test_basket['input_ids'] = dataset_test.input_ids[0]\n","test_basket['attention_mask'] = dataset_test.attn_mask[0]\n","loader_test = tf.data.Dataset.from_tensor_slices(test_basket).batch(params['batch_size'])   \n","loop_test = notebook.tqdm(loader_test, position=0, leave=True, colour='yellow')\n","\n","#create top_k matrix for predictions in test set\n","top_k_all = np.zeros((test_size,30),dtype=np.int32)\n","missing_items_all = np.zeros((test_size),dtype=np.int32)\n","top_1_list,top_k_list,top_n_list = [],[],[]\n","\n","for k, batch_test in enumerate(loop_test):\n","  batch_size = len(batch_test['input_ids'])\n","  total_batches += batch_size\n","  non_predict = tf.fill((batch_size,num_specialtok),0.0)\n","  incomplete_ids_test = batch_test['input_ids'][:,0:-1]\n","  incomplete_mask_test = batch_test['attention_mask'][:,0:-1]\n","  missing_items_test = batch_test['input_ids'][:,-1]\n","  outputG = netG.call(input_ids=incomplete_ids_test,\n","                      attention_mask=incomplete_mask_test,\n","                      training = False).logits[:,-1,num_specialtok:]\n","\n","  #model should not predict special tokens, therefore, set softmax value at zero\n","  outputG_softmax = tf.concat((non_predict, tf.nn.softmax(outputG)), axis=-1)\n","  top_k = tf.nn.top_k(outputG_softmax, k=30, sorted=True)[1]\n","  top_k_items = tf.squeeze(top_k)\n","  for i in range(batch_size):\n","    top_k_all[(k*batch_size)+i,:] =  top_k_items[i]\n","    missing_items_all[(k*batch_size)+i] = missing_items_test[i]\n","\n","  # calculate (normal) prec@k\n","  for i in range(0,batch_size):\n","    top_n_list.append([batch_test['input_ids'][i],batch_test['attention_mask'][i],top_k_items[i]])\n","    top_1_count += int(top_k_items[i][0] == missing_items_test[i])\n","    for j in range(6):\n","      if (top_k_items[i][j] == missing_items_test[i]):\n","        top_k_count += 1\n","        break\n","\n","  # calculate adj. prec@k\n","  top_k_names = getProductNames(top_k_items)\n","  real_names = getProductNames_Real(missing_items_test)\n","  for i in range(batch_size):\n","    real_name = real_names[i]\n","    top_k_item = top_k_names[i]\n","    if real_name == \"NOT AVAILABLE\":\n","      real_token = missing_items_test[i]\n","      top_k_token = top_k_items[i]\n","      if real_token == top_k_token[0]:\n","        top_1_count_adj +=1\n","      for j in range(6):\n","        if real_token == top_k_token[j]:\n","          top_k_count_adj += 1\n","          break\n","    else:\n","      predict_names, ngrams = [], dict()\n","      q, t = 0,0\n","      ngram_correct = ngram(real_name)\n","      short=False\n","      while len(predict_names)!=6 and q!=len(top_k_item) and short!=True:\n","        if len(top_k_item)<=6:\n","          short=True\n","          predict_names = top_k_item\n","          for w, item in enumerate(predict_names):\n","            ngram_item = ngram(item)\n","            ngrams.update({w : ngram_item})\n","        else:\n","          item = top_k_item[q]   \n","          ngram_item = ngram(item)\n","          if q==0:\n","            predict_names.append(item)\n","            ngrams.update({t : ngram_item})\n","            t+=1\n","          else:\n","            sim = [dice_coef(ngram_item, value) for value in ngrams.values()]\n","            if all(z<params['ngram_sim'] for z in sim):\n","              ngrams.update({t : ngram_item})\n","              predict_names.append(item)\n","              t+=1\n","\n","          q+=1\n","        \n","      for key, value in ngrams.items():\n","        ngram_sim = dice_coef(ngram_correct, value)\n","        if ngram_sim >= params['ngram_sim']:\n","          output_want = [real_name] + predict_names\n","          output[total_batches-batch_size+i] = output_want\n","          top_k_count_adj+=1\n","          top_k_list.append([batch_test['input_ids'][i],batch_test['attention_mask'][i],top_k_items[i]])\n","          if key==0:\n","            top_1_count_adj+=1\n","            top_1_list.append([batch_test['input_ids'][i],batch_test['attention_mask'][i],top_k_items[i]])\n","          break\n","  \n","  for i in range(0,batch_size):\n","    pr = tf.math.reduce_sum(tf.where(tf.math.less(outputG_softmax[i,:], outputG_softmax[i,missing_items_test[i].numpy()]), 1.0, 0.0)).numpy()/tokenizer.vocab_size\n","    pr_ls_test.append(pr)\n","  precK_test = top_k_count/(total_batches)\n","\n","  mpr_test = np.array(pr_ls_test).sum()/(total_batches) \n","\n","  loop_test.set_postfix(PrecisionAtK =round(precK_test,4), Correct=top_k_count,  data=\"Test\", MPR = mpr_test)\n","\n","#print metrics\n","mpr_test = np.array(pr_ls_test).sum()/test_size\n","prec1 = (top_1_count/test_size) * 100\n","prec6 = (top_k_count/test_size) * 100\n","prec1_adj = (top_1_count_adj/test_size) * 100\n","prec6_adj = ((top_k_count_adj)/test_size) * 100\n","print(f\"   Mean Percentile Rank: {mpr_test}\")\n","print(f\"     precision at 1 (%): {prec1}\")\n","print(f\"     precision at 6 (%): {prec6}\")\n","print(f\"adj. precision at 1 (%): {prec1_adj}\")\n","print(f\"adj. precision at 6 (%): {prec6_adj}\")"],"metadata":{"id":"R5NLPDl4AYax"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"tf_HAMSTER_BCE (labels flipped).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5c6788948c384d59929380ca15c422da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc18555b6caf4c2a8e18a0fecec5a25a","IPY_MODEL_a734f47d5a5848e18c42fcd10c83d3da","IPY_MODEL_08687923c9934e5a9dbb8a6f76904629"],"layout":"IPY_MODEL_91af8b48709748d189b9fa4d9a4e4d8d"}},"bc18555b6caf4c2a8e18a0fecec5a25a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac9eb333a0545d58649b0a272b9ea1b","placeholder":"​","style":"IPY_MODEL_319b495826fc4c99a03aff2366c9c71d","value":"100%"}},"a734f47d5a5848e18c42fcd10c83d3da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_32201219aaf041f1913bf26b9db8696b","max":25000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89c97ed70d7a4d7e8b895d42355aac4c","value":25000}},"08687923c9934e5a9dbb8a6f76904629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5266621c94d64ca99ba067af2f0d1da9","placeholder":"​","style":"IPY_MODEL_d14e53dcd90243b4a6e6945218270db9","value":" 25000/25000 [7:21:26&lt;00:00,  1.12s/it, D_correct_ratio=0.753, G_correct_at1=3019, G_total_correct=11258, clipD=0.799, clipG=0.652, data=train, epochs=1, fake_correct_D=76631, lossD=1.15, lossG=-923, lrD=2.39e-6, lrG=2.18e-6, precK=0.113, real_correct_D=73937]"}},"91af8b48709748d189b9fa4d9a4e4d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ac9eb333a0545d58649b0a272b9ea1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"319b495826fc4c99a03aff2366c9c71d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32201219aaf041f1913bf26b9db8696b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c97ed70d7a4d7e8b895d42355aac4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":"green","description_width":""}},"5266621c94d64ca99ba067af2f0d1da9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14e53dcd90243b4a6e6945218270db9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}